{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6821552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-08-09 17:38:05--  https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
      "dl.fbaipublicfiles.com (dl.fbaipublicfiles.com) をDNSに問いあわせています... 3.173.197.128, 3.173.197.49, 3.173.197.101, ...\n",
      "dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.173.197.128|:443 に接続しています... 接続しました。\n",
      "HTTP による接続要求を送信しました、応答を待っています... 200 OK\n",
      "長さ: 2564550879 (2.4G) [binary/octet-stream]\n",
      "`sam_vit_h_4b8939.pth' に保存中\n",
      "\n",
      "sam_vit_h_4b8939.pt 100%[===================>]   2.39G  9.79MB/s 時間 4m 20s     \n",
      "\n",
      "2025-08-09 17:42:25 (9.40 MB/s) - `sam_vit_h_4b8939.pth' へ保存完了 [2564550879/2564550879]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e162322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ MPS detected: Patching apply_coords to return float32\n",
      "✅ Saved: /Users/Kota/blended/Team3AmazonProject/data/temp/cropped_sam/Table--154-_jpg.rf.67264c7a7b156dd01c44e5e35de6cbe9_sam_cropped.png\n",
      "✅ Saved: /Users/Kota/blended/Team3AmazonProject/data/temp/cropped_sam/Table--154-_jpg.rf.67264c7a7b156dd01c44e5e35de6cbe9_sam_cropped.png\n",
      "✅ Saved: /Users/Kota/blended/Team3AmazonProject/data/temp/cropped_sam/Sofa--348-_jpg.rf.74a1bda29972fc468b85d6c9eab48bbd_sam_cropped.png\n",
      "✅ Saved: /Users/Kota/blended/Team3AmazonProject/data/temp/cropped_sam/Sofa--348-_jpg.rf.74a1bda29972fc468b85d6c9eab48bbd_sam_cropped.png\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 57\u001b[39m\n\u001b[32m     54\u001b[39m image_rgb = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# マスク生成\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m masks = \u001b[43mmask_generator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_rgb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m masks:\n\u001b[32m     59\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m❌ No mask detected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_path.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/blended/Team3AmazonProject/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/blended/Team3AmazonProject/.venv/lib/python3.13/site-packages/segment_anything/automatic_mask_generator.py:163\u001b[39m, in \u001b[36mSamAutomaticMaskGenerator.generate\u001b[39m\u001b[34m(self, image)\u001b[39m\n\u001b[32m    138\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    139\u001b[39m \u001b[33;03mGenerates masks for the given image.\u001b[39;00m\n\u001b[32m    140\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    159\u001b[39m \u001b[33;03m         the mask, given in XYWH format.\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    162\u001b[39m \u001b[38;5;66;03m# Generate masks\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m mask_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_masks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;66;03m# Filter small disconnected regions and holes in masks\u001b[39;00m\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.min_mask_region_area > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/blended/Team3AmazonProject/.venv/lib/python3.13/site-packages/segment_anything/automatic_mask_generator.py:206\u001b[39m, in \u001b[36mSamAutomaticMaskGenerator._generate_masks\u001b[39m\u001b[34m(self, image)\u001b[39m\n\u001b[32m    204\u001b[39m data = MaskData()\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m crop_box, layer_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(crop_boxes, layer_idxs):\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m     crop_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_crop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrop_box\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m     data.cat(crop_data)\n\u001b[32m    209\u001b[39m \u001b[38;5;66;03m# Remove duplicate masks between crops\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/blended/Team3AmazonProject/.venv/lib/python3.13/site-packages/segment_anything/automatic_mask_generator.py:245\u001b[39m, in \u001b[36mSamAutomaticMaskGenerator._process_crop\u001b[39m\u001b[34m(self, image, crop_box, crop_layer_idx, orig_size)\u001b[39m\n\u001b[32m    243\u001b[39m data = MaskData()\n\u001b[32m    244\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m (points,) \u001b[38;5;129;01min\u001b[39;00m batch_iterator(\u001b[38;5;28mself\u001b[39m.points_per_batch, points_for_image):\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m     batch_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcropped_im_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrop_box\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    246\u001b[39m     data.cat(batch_data)\n\u001b[32m    247\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m batch_data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/blended/Team3AmazonProject/.venv/lib/python3.13/site-packages/segment_anything/automatic_mask_generator.py:297\u001b[39m, in \u001b[36mSamAutomaticMaskGenerator._process_batch\u001b[39m\u001b[34m(self, points, im_size, crop_box, orig_size)\u001b[39m\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pred_iou_thresh > \u001b[32m0.0\u001b[39m:\n\u001b[32m    296\u001b[39m     keep_mask = data[\u001b[33m\"\u001b[39m\u001b[33miou_preds\u001b[39m\u001b[33m\"\u001b[39m] > \u001b[38;5;28mself\u001b[39m.pred_iou_thresh\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m     \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeep_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[38;5;66;03m# Calculate stability score\u001b[39;00m\n\u001b[32m    300\u001b[39m data[\u001b[33m\"\u001b[39m\u001b[33mstability_score\u001b[39m\u001b[33m\"\u001b[39m] = calculate_stability_score(\n\u001b[32m    301\u001b[39m     data[\u001b[33m\"\u001b[39m\u001b[33mmasks\u001b[39m\u001b[33m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m.predictor.model.mask_threshold, \u001b[38;5;28mself\u001b[39m.stability_score_offset\n\u001b[32m    302\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/blended/Team3AmazonProject/.venv/lib/python3.13/site-packages/segment_anything/utils/amg.py:49\u001b[39m, in \u001b[36mMaskData.filter\u001b[39m\u001b[34m(self, keep)\u001b[39m\n\u001b[32m     47\u001b[39m     \u001b[38;5;28mself\u001b[39m._stats[k] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, torch.Tensor):\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     \u001b[38;5;28mself\u001b[39m._stats[k] = v[torch.as_tensor(keep, device=v.device)]\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, np.ndarray):\n\u001b[32m     51\u001b[39m     \u001b[38;5;28mself\u001b[39m._stats[k] = v[keep.detach().cpu().numpy()]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from segment_anything import SamPredictor, sam_model_registry, SamAutomaticMaskGenerator\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from types import MethodType  # 追加\n",
    "\n",
    "# 入出力\n",
    "input_dir = Path(\"/Users/Kota/blended/Team3AmazonProject/data/temp/original\")\n",
    "output_dir = Path(\"/Users/Kota/blended/Team3AmazonProject/data/temp/cropped_sam\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# SAMモデル\n",
    "sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
    "model_type = \"vit_h\"\n",
    "\n",
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)\n",
    "\n",
    "# ★ MPS対策：apply_coordsの戻りを必ずfloat32に（ライブラリは未修正のまま）\n",
    "if device == \"mps\":\n",
    "    print(\"⚠️ MPS detected: Patching apply_coords to return float32\")\n",
    "    orig_apply_coords = mask_generator.predictor.transform.apply_coords\n",
    "\n",
    "    def apply_coords_float32(self, coords, size):\n",
    "        out = orig_apply_coords(coords, size)\n",
    "        # numpy配列のままfloat32へ\n",
    "        return out.astype(np.float32)\n",
    "\n",
    "    mask_generator.predictor.transform.apply_coords = MethodType(\n",
    "        apply_coords_float32, mask_generator.predictor.transform\n",
    "    )\n",
    "\n",
    "# 画像拡張子\n",
    "image_exts = {\".jpg\", \".png\"}\n",
    "\n",
    "for img_path in input_dir.glob(\"*\"):\n",
    "    if img_path.suffix.lower() not in image_exts:\n",
    "        continue\n",
    "\n",
    "    original = cv2.imread(str(img_path))\n",
    "    if original is None:\n",
    "        print(f\"⚠️ Failed to read: {img_path}\")\n",
    "        continue\n",
    "\n",
    "    # SAMはRGBのuint8でOK。float32化は不要・逆効果\n",
    "    image_rgb = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # マスク生成\n",
    "    masks = mask_generator.generate(image_rgb)\n",
    "    if not masks:\n",
    "        print(f\"❌ No mask detected: {img_path.name}\")\n",
    "        continue\n",
    "\n",
    "    # 一番大きいマスクを採用\n",
    "    largest_mask = max(masks, key=lambda x: x[\"area\"])\n",
    "    mask = largest_mask[\"segmentation\"].astype(np.uint8)\n",
    "\n",
    "    # マスク適用（黒背景）\n",
    "    mask_3c = np.stack([mask] * 3, axis=-1)\n",
    "    masked_img = original * mask_3c\n",
    "\n",
    "    save_path = output_dir / f\"{img_path.stem}_sam_cropped.png\"\n",
    "    cv2.imwrite(str(save_path), masked_img)\n",
    "    print(f\"✅ Saved: {save_path}\")\n",
    "\n",
    "print(\"SAM segmentation completed!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "team3amazonproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
